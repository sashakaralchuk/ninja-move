{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import json\n",
    "import time\n",
    "\n",
    "import mplfinance as mpf\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy as sa\n",
    "\n",
    "import shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_clickhouse = \"clickhouse+native://default@clickhouse-1:9000/default\"\n",
    "engine_clickhouse = sa.create_engine(url_clickhouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trade_emas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"520cec67-0632-4f3d-bf8e-d2b140f8946b\"\n",
    "debugs_candles_df = (\n",
    "    pd.read_sql_query(\n",
    "        \"\"\"\n",
    "        SELECT *\n",
    "        FROM default.debugs\n",
    "        WHERE run_id = %(run_id)s AND kind = 'candle';\n",
    "        \"\"\",\n",
    "        engine_clickhouse,\n",
    "        params={\"run_id\": run_id},\n",
    "    )\n",
    "    .assign(\n",
    "        c=lambda x: x.content.apply(json.loads),\n",
    "        timestamp=lambda x: x.c.apply(\n",
    "            lambda x: dt.datetime.fromtimestamp(x[\"open_time\"] / 1000)\n",
    "        ),\n",
    "        open=lambda x: x.c.apply(lambda x: x[\"open\"]),\n",
    "        close=lambda x: x.c.apply(lambda x: x[\"close\"]),\n",
    "        low=lambda x: x.c.apply(lambda x: x[\"low\"]),\n",
    "        high=lambda x: x.c.apply(lambda x: x[\"high\"]),\n",
    "    )\n",
    "    .set_index(\"timestamp\")\n",
    "    .sort_index()\n",
    ")\n",
    "backtest_df = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "    SELECT *\n",
    "    FROM default.debugs\n",
    "    WHERE run_id = %(run_id)s AND kind = 'backtest'\n",
    "    \"\"\",\n",
    "    engine_clickhouse,\n",
    "    params={\"run_id\": run_id},\n",
    ").assign(\n",
    "    c=lambda x: x.content.apply(json.loads),\n",
    "    open_price=lambda x: x.c.apply(lambda x: x[\"open_price\"]),\n",
    "    open_timestamp_millis=lambda x: x.c.apply(lambda x: x[\"open_timestamp_millis\"]),\n",
    "    close_timestamp_millis=lambda x: x.c.apply(lambda x: x[\"close_timestamp_millis\"]),\n",
    "    reason=lambda x: x.c.apply(lambda x: x[\"reason\"]),\n",
    "    bottom_threshold=lambda x: x.c.apply(lambda x: x.get(\"bottom_threshold\", 0.0)),\n",
    "    trailing_threshold=lambda x: x.c.apply(lambda x: x.get(\"trailing_threshold\", 0.0)),\n",
    ")\n",
    "profit_df = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        JSONExtractFloat(content, 'open_price') open_price,\n",
    "        COALESCE(\n",
    "            JSONExtract(content, 'bottom_threshold', 'Nullable(Float64)'),\n",
    "            JSONExtract(content, 'trailing_threshold', 'Nullable(Float64)'),\n",
    "            -1.0\n",
    "        ) close_price,\n",
    "        close_price - open_price profit\n",
    "    FROM default.debugs\n",
    "    WHERE run_id = %(run_id)s AND kind = 'backtest'\n",
    "    \"\"\",\n",
    "    engine_clickhouse,\n",
    "    params={\"run_id\": run_id},\n",
    ")\n",
    "alines_list = [\n",
    "    [\n",
    "        (dt.datetime.fromtimestamp(row.open_timestamp_millis / 1000), row.open_price),\n",
    "        (\n",
    "            dt.datetime.fromtimestamp(row.close_timestamp_millis / 1000),\n",
    "            row.bottom_threshold or row.trailing_threshold,\n",
    "        ),\n",
    "    ]\n",
    "    for _, row in backtest_df.iterrows()\n",
    "]\n",
    "alines_colors = [\"g\" if x[1][1] - x[0][1] > 0 else \"r\" for x in alines_list]\n",
    "fig, axs = mpf.plot(\n",
    "    debugs_candles_df,\n",
    "    warn_too_much_data=len(debugs_candles_df),\n",
    "    type=\"candle\",\n",
    "    figsize=(140, 40),\n",
    "    style=shared.s,\n",
    "    ema=12,\n",
    "    alines={\"alines\": alines_list, \"colors\": alines_colors, \"linewidths\": 5},\n",
    "    returnfig=True,\n",
    ")\n",
    "xticks = pd.date_range(\n",
    "    debugs_candles_df.index.min(), debugs_candles_df.index.max(), freq=\"1h\"\n",
    ")\n",
    "xticks_locations = [debugs_candles_df.index.get_loc(tick) for tick in xticks]\n",
    "xticks_labels = [tick.isoformat() for tick in xticks]\n",
    "_ = axs[-2].xaxis.set_ticks(xticks_locations)\n",
    "_ = axs[-2].set_xticklabels(xticks_labels, fontsize=5, rotation=90)\n",
    "print(f\"profit: {profit_df.profit.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugs_candles_df.head(1)\n",
    "# backtest_df.head(1)\n",
    "# profit_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clickhouse DDLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "rpk topic create trades\n",
    "\n",
    "CREATE TABLE default.trades_binance_raw\n",
    "(\n",
    "  read_topic String,\n",
    "  read_error String,\n",
    "  read_raw_message String,\n",
    "  open_time DateTime,\n",
    "  open Float64,\n",
    "  high Float64,\n",
    "  low Float64,\n",
    "  close Float64,\n",
    "  volume Float64,\n",
    "  kline_close_time DateTime,\n",
    "  quote_asset_volume Float64,\n",
    "  number_of_trades Int64,\n",
    "  taker_buy_base_asset_volume Float64,\n",
    "  taker_buy_quote_asset_volume Float64,\n",
    "  t Int64,\n",
    "  symbol String,\n",
    "  date_iso Date\n",
    ")\n",
    "ENGINE = MergeTree\n",
    "PARTITION BY toDate(open_time)\n",
    "ORDER BY toDate(open_time);\n",
    "\n",
    "CREATE MATERIALIZED VIEW default.trades_binance_mv\n",
    "TO default.trades_binance_raw AS\n",
    "SELECT\n",
    "  _topic read_topic,\n",
    "  _error read_error,\n",
    "  _raw_message read_raw_message,\n",
    "  fromUnixTimestamp64Milli(JSONExtractUInt(data, 'open_time')) open_time,\n",
    "  JSONExtractFloat(data, 'open') open,\n",
    "  JSONExtractFloat(data, 'high') high,\n",
    "  JSONExtractFloat(data, 'low') low,\n",
    "  JSONExtractFloat(data, 'close') close,\n",
    "  JSONExtractFloat(data, 'volume') volume,\n",
    "  fromUnixTimestamp64Milli(toInt64(JSONExtractFloat(data, 'kline_close_time'))) kline_close_time,\n",
    "  JSONExtractFloat(data, 'quote_asset_volume') quote_asset_volume,\n",
    "  JSONExtractUInt(data, 'number_of_trades') number_of_trades,\n",
    "  JSONExtractFloat(data, 'taker_buy_base_asset_volume') taker_buy_base_asset_volume,\n",
    "  JSONExtractFloat(data, 'taker_buy_quote_asset_volume') taker_buy_quote_asset_volume,\n",
    "  JSONExtractUInt(data, 't') t,\n",
    "  JSONExtractString(data, 'symbol') symbol,\n",
    "  toDate(JSONExtractString(data, 'date_iso')) date_iso\n",
    "FROM default.trades_binance_queue;\n",
    "\n",
    "\n",
    "CREATE TABLE default.trades_raw\n",
    "(\n",
    "  read_topic String,\n",
    "  read_error String,\n",
    "  read_raw_message String,\n",
    "  id UInt64,\n",
    "  price Float64,\n",
    "  qty Float64,\n",
    "  base_qty Float64,\n",
    "  time DateTime,\n",
    "  is_buyer Bool,\n",
    "  is_maker Bool,\n",
    "  exchange String,\n",
    "  symbol String,\n",
    "  date_iso Date\n",
    ")\n",
    "ENGINE = ReplacingMergeTree\n",
    "PRIMARY KEY (id)\n",
    "PARTITION BY toDate(time);\n",
    "\n",
    "CREATE TABLE default.trades_queue\n",
    "(data String)\n",
    "ENGINE = Kafka\n",
    "SETTINGS kafka_broker_list = 'redpanda-1:9093',\n",
    "         kafka_topic_list = 'trades',\n",
    "         kafka_group_name = 'clickhouse-consumer',\n",
    "         kafka_format = 'JSONAsString',\n",
    "         kafka_thread_per_consumer = 0,\n",
    "         kafka_num_consumers = 1,\n",
    "         kafka_handle_error_mode = 'stream',\n",
    "         kafka_max_block_size = 100000;\n",
    "\n",
    "CREATE MATERIALIZED VIEW default.trades_mv\n",
    "TO default.trades_raw AS\n",
    "SELECT\n",
    "  _topic read_topic,\n",
    "  _error read_error,\n",
    "  _raw_message read_raw_message,\n",
    "  JSONExtractUInt(data, 'id') id,\n",
    "  JSONExtractFloat(data, 'price') price,\n",
    "  JSONExtractFloat(data, 'qty') qty,\n",
    "  JSONExtractFloat(data, 'base_qty') base_qty,\n",
    "  fromUnixTimestamp64Milli(JSONExtractUInt(data, 'time')) time,\n",
    "  JSONExtractBool(data, 'is_buyer') is_buyer,\n",
    "  JSONExtractBool(data, 'is_maker') is_maker,\n",
    "  JSONExtractString(data, 'exchange') exchange,\n",
    "  JSONExtractString(data, 'symbol') symbol,\n",
    "  toDate(JSONExtractString(data, 'date_iso')) date_iso\n",
    "FROM default.trades_queue;\n",
    "\n",
    "\n",
    "CREATE TABLE default.debugs\n",
    "(\n",
    "run_id String,\n",
    "kind String,\n",
    "content String\n",
    ")\n",
    "ENGINE = Log;\n",
    "\n",
    "\n",
    "CREATE TABLE default.trades_t_raw\n",
    "(\n",
    "  id UInt64,\n",
    "  price Float64,\n",
    "  qty Float64,\n",
    "  base_qty Float64,\n",
    "  time DateTime,\n",
    "  is_buyer Bool,\n",
    "  is_maker Bool,\n",
    "  exchange String,\n",
    "  symbol String,\n",
    "  date_iso Date\n",
    ")\n",
    "ENGINE = ReplacingMergeTree\n",
    "PRIMARY KEY (id)\n",
    "PARTITION BY toDate(time);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bybit funding rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time_secs = int(time.time())\n",
    "start_time_secs = end_time_secs - 60 * 60 * 24 * 7\n",
    "window_secs = 60 * 60\n",
    "shift_secs = 0\n",
    "eth_funding_rates_responses = []\n",
    "while start_time_secs + shift_secs <= end_time_secs:\n",
    "    # curl 'https://api-testnet.bybit.com/v5/market/funding/history?category=linear&symbol=ETHPERP&limit=1' | python3.10 -m json.tool\n",
    "    url = (\n",
    "        \"https://api.bybit.com\"\n",
    "        \"/v5/market/funding/history?category=linear&symbol=ETHPERP&limit=1\"\n",
    "        f\"&startTime={(start_time_secs + shift_secs)*1000}\"\n",
    "        f\"&endTime={(start_time_secs + shift_secs + window_secs) * 1000}\"\n",
    "    )\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    eth_funding_rates_responses.append(res.json())\n",
    "    shift_secs += window_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [\n",
    "    # (x[\"symbol\"], int(x[\"fundingRateTimestamp\"]), float(x[\"fundingRate\"]))\n",
    "    x\n",
    "    for res in eth_funding_rates_responses\n",
    "    for x in res[\"result\"][\"list\"]\n",
    "]\n",
    "(\n",
    "    pd.DataFrame(l)\n",
    "    .sort_values(by=[\"fundingRateTimestamp\"])\n",
    "    .assign(\n",
    "        event_timestamp=lambda x: x.fundingRateTimestamp.astype(int).apply(\n",
    "            lambda x: dt.datetime.fromtimestamp(x / 1000)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### commands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run --rm -p 8888:8888 -v \"$(pwd)/jupy/.var\":/home/jovyan/.var jupyterhub/singleuser:4.0.0b2 start-notebook.sh --NotebookApp.password=\\\"sha1:f8409da91c32:bab6de2e611c36ac6b49d3f8d8229689cd9d5474\\\"\n",
    "# pip install spylon-kernel pandas==2.2.0 matplotlib==3.8.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
